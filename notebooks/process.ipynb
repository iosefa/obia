{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-03T00:26:19.219470Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from obia.handlers import open_geotiff\n",
    "from obia.segment import segment\n",
    "from obia.classify import classify"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77d470450cf678aa",
   "metadata": {},
   "source": [
    "def reassign_class(x):\n",
    "    if x not in keep_classes:\n",
    "        return 0\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "start_time = time.time()\n",
    "max_obs = 2000\n",
    "\n",
    "training_path = \"/mnt/c/tmp/output/Merge2.geojson\"\n",
    "\n",
    "keep_classes = [1, 2, 4, 8, 9, 12, 13, 16]\n",
    "training_segments = gpd.read_file(training_path)\n",
    "training_segments = training_segments.dropna()\n",
    "\n",
    "training_segments = training_segments.drop(columns=['OBJECTID', 'Shape_Length', 'Shape_Area'])\n",
    "training_segments['feature_class'] = training_segments['feature_class'].apply(reassign_class)\n",
    "\n",
    "classes = training_segments['feature_class'].unique()\n",
    "\n",
    "for cls in classes:\n",
    "    count = training_segments[training_segments['feature_class'] == cls].shape[0]\n",
    "\n",
    "    if count > max_obs:\n",
    "        drop_indices = training_segments[training_segments['feature_class'] == cls].index[max_obs:]\n",
    "        training_segments = training_segments.drop(drop_indices)\n",
    "\n",
    "\n",
    "\n",
    "raster_path = \"/mnt/c/tmp/output/output_163.tif\"\n",
    "\n",
    "image = open_geotiff(raster_path)\n",
    "segmented_image = segment(\n",
    "    image, segmentation_bands=[7,4,1],\n",
    "    method=\"slic\", n_segments=25000, compactness=10, max_num_iter=100, sigma=0.5, convert2lab=True, slic_zero=True\n",
    ")\n",
    "classified = classify(image, segmented_image, training_segments, method='mlp', compute_shap=True, solver='lbfgs')\n",
    "classified.write_geotiff(\"/mnt/c/tmp/output/classified_163.tif\")\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Elapsed time: {elapsed_time}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2647332b-0cc8-44d1-8df6-816d9f18b4fc",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import shap\n",
    "\n",
    "from PIL.Image import fromarray\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from obia.handlers import _write_geotiff\n",
    "\n",
    "\n",
    "class ClassifiedImage:\n",
    "    classified_image = None\n",
    "    confusion_matrix = None\n",
    "    report = None\n",
    "    params = None\n",
    "    shap_values = None\n",
    "    crs = None\n",
    "    transform = None\n",
    "\n",
    "    def __init__(self, classified_image, confusion_matrix, report, shap_values, transform, crs, params):\n",
    "        self.classified_image = classified_image\n",
    "        self.report = report\n",
    "        self.confusion_matrix = confusion_matrix\n",
    "        self.shap_values = shap_values\n",
    "        self.params = params\n",
    "        self.transform = transform\n",
    "        self.crs = crs\n",
    "\n",
    "    def write_geotiff(self, output_path):\n",
    "        _write_geotiff(self.classified_image, output_path, self.crs, self.transform)\n",
    "\n",
    "\n",
    "def classify(image, segmented_image, training_classes,\n",
    "             method='rf', test_size=0.5, compute_reports=False,\n",
    "             compute_shap=False, **kwargs):\n",
    "    shap_values = None\n",
    "    x = training_classes.drop(['feature_class', 'geometry', 'segment_id'], axis=1)\n",
    "    y = training_classes['feature_class']\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, random_state=42)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x_train)  # Fit scaler to training data\n",
    "    x_train = scaler.transform(x_train)\n",
    "    x_test = scaler.transform(x_test) \n",
    "\n",
    "    if method == 'rf':\n",
    "        classifier = RandomForestClassifier(**kwargs)\n",
    "    elif method == 'mlp':\n",
    "        classifier = MLPClassifier(**kwargs)\n",
    "    else:\n",
    "        raise ValueError('An unsupported classification algorithm was requested')\n",
    "\n",
    "    classifier.fit(x_train, y_train)\n",
    "    if compute_shap:\n",
    "        explainer = None\n",
    "        if isinstance(classifier, RandomForestClassifier):\n",
    "            explainer = shap.TreeExplainer(classifier)\n",
    "        elif isinstance(classifier, MLPClassifier):\n",
    "            explainer = shap.KernelExplainer(classifier.predict_proba, x_train)\n",
    "\n",
    "        shap_values = explainer(x_train)\n",
    "\n",
    "    y_pred = classifier.predict(x_test)\n",
    "\n",
    "    report = None\n",
    "    cm = None\n",
    "    if compute_reports:\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        report = classification_report(y_test, y_pred)\n",
    "\n",
    "\n",
    "    df = segmented_image.segments[list(training_classes.columns.values)]\n",
    "    \n",
    "    x_pred = df.drop(['feature_class', 'geometry', 'segment_id'], axis=1, errors='ignore')\n",
    "    x_pred = scaler.transform(x_pred)\n",
    "\n",
    "    y_pred_all = classifier.predict(x_pred)\n",
    "\n",
    "    params = classifier.get_params()\n",
    "    segment_ids = df['segment_id'].to_list()\n",
    "\n",
    "    classified_img = np.zeros((image.img_data.shape[0], image.img_data.shape[1]))\n",
    "\n",
    "    for i, segment_id in enumerate(segment_ids):\n",
    "        idx = np.argwhere(segmented_image._segments == segment_id)\n",
    "        for j in idx:\n",
    "            classified_img[j[0], j[1]] = y_pred_all[i]\n",
    "\n",
    "    return ClassifiedImage(classified_img, cm, report, shap_values, image.transform, image.crs, params)\n",
    "\n",
    "\n",
    "# todo: add CNN classifier. Follow procedure of https://www.mdpi.com/2072-4292/13/14/2709#. simply plot each segment and assign a class then classify each plotted segment. seems super inneficient, but maybe more powerful? probably not though. RF or MLP should be just as good... but maybe not."
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77589671-59f1-45d2-af3f-aa91da17fff2",
   "metadata": {},
   "source": [
    "training_segments = gpd.read_file(training_path)\n",
    "training_segments = training_segments.dropna()\n",
    "training_segments['feature_class'].dtype"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6f604ce5-f84b-4948-be94-107f5cf4e0a6",
   "metadata": {},
   "source": [
    "list(training_segments.columns.values)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "dc71bdbf-0850-4af0-9c93-85f31d1fdfcc",
   "metadata": {},
   "source": [
    "def reassign_class(x):\n",
    "    if x not in keep_classes:\n",
    "        return 0\n",
    "    else:\n",
    "        return x\n",
    "        \n",
    "# keep_classes = [1, 2, 4, 8, 9, 12, 13, 16]\n",
    "keep_classes = [1, 2, 4, 8, 9]\n",
    "drop_classes = [16, 3, 5, 6, 7, 10, 13, 14, 15]\n",
    "\n",
    "# training = training_segments.drop(columns=['OBJECTID', 'Shape_Length', 'Shape_Area',])\n",
    "columns_to_keep = [\n",
    "    'segment_id', 'feature_class',\n",
    "    'b1_mean', \n",
    "    'b4_mean',\n",
    "    'b7_mean', \n",
    "    'b7_dissimilarity',\n",
    "    'b7_correlation',\n",
    "    'geometry'\n",
    "    ]\n",
    "\n",
    "training = training_segments[columns_to_keep]\n",
    "training = training[~training['feature_class'].isin(drop_classes)]\n",
    "\n",
    "training['feature_class'] = training['feature_class'].astype(int)\n",
    "\n",
    "training['feature_class'] = training['feature_class'].apply(reassign_class)\n",
    "classes = training['feature_class'].unique()\n",
    "\n",
    "training['feature_class'].value_counts()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3758d289-b571-4264-bf2f-6ac34c70865a",
   "metadata": {},
   "source": [
    "training.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "00778c83-af1c-4408-9480-6c1e3a3cd45a",
   "metadata": {},
   "source": [
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.features import shapes\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def raster_to_vector(raster, value, transform):\n",
    "    \"\"\"\n",
    "    Convert a raster into a vector (Polygon).\n",
    "\n",
    "    Args:\n",
    "        raster(numpy.array): A 2D numpy array representing the raster.\n",
    "        value(int): Value of pixels to be used for generating polygons.\n",
    "        transform (Affine): A rasterio.Affine class instance representing the transformation matrix.\n",
    "\n",
    "    Returns:\n",
    "        Geopandas GeoDataFrame representation.\n",
    "    \"\"\"\n",
    "    mask = None if value is None else (raster == value)\n",
    "    shapes_gen = shapes(raster, mask=mask, transform=transform)\n",
    "    poly_dict_list = []\n",
    "    for poly_dict, val in shapes_gen:\n",
    "        new_dict = {'properties': {'value': val}, 'geometry': poly_dict}\n",
    "        poly_dict_list.append(new_dict)\n",
    "    vector_df = gpd.GeoDataFrame.from_features(poly_dict_list)\n",
    "    return vector_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def write_vector_to_geopackage(vector, filepath):\n",
    "    \"\"\"\n",
    "    Write a vector into a geopackage file (.gpkg).\n",
    "\n",
    "    Args:\n",
    "        vector(GeoDataFrame): The vector data in GeoDataFrame format.\n",
    "        filepath(str): The file path where the results should be written.\n",
    "    \"\"\"\n",
    "    vector.to_file(filepath, driver='GPKG')\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3c063090-6bb5-4720-8cc0-bb5066665fe8",
   "metadata": {},
   "source": [
    "classified = classify(image, segmented_image, training, method='mlp', compute_shap=False, hidden_layer_sizes=(100, ), solver='lbfgs', max_iter=10000)\n",
    "\n",
    "vector = raster_to_vector(classified.classified_image.astype(np.int16), None, image.transform)\n",
    "\n",
    "write_vector_to_geopackage(vector, \"/mnt/c/tmp/output/classified_163_4.gpkg\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "896523e2-61fb-40f6-a87c-a36f496a5ab2",
   "metadata": {},
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "im = image.to_image(bands=[4, 2, 1])\n",
    "axs[0].imshow(im)\n",
    "axs[0].axis('off')\n",
    "axs[0].set_title('Original Image')\n",
    "\n",
    "axs[1].imshow(classified.classified_image, cmap='Set1')\n",
    "axs[1].axis('off')\n",
    "axs[1].set_title('Classified Image') \n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "078f44ac-e29c-40fc-aff5-8d13e1467e42",
   "metadata": {},
   "source": [
    "classified.write_geotiff(\"/mnt/c/tmp/output/classified_163_2.tif\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "12cc9ffc-0822-487b-a30f-154317a54db4",
   "metadata": {},
   "source": [
    "np.unique(classified.classified_image)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58b9c09-7ecb-4733-b26e-af64a14a1962",
   "metadata": {},
   "source": [
    "vars = training_segments.drop(['feature_class', 'geometry', 'segment_id'], axis=1, errors='ignore')\n",
    "shap_values = classified.shap_values\n",
    "shap.summary_plot(\n",
    "    [shap_values[:, :, class_ind].values for class_ind in range(shap_values.shape[-1])],\n",
    "    feature_names=vars.columns\n",
    ")"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
